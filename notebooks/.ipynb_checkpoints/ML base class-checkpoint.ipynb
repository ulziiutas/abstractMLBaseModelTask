{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme()\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.abstractMLBaseModel import abstractMLBaseModel\n",
    "from packages.functionality_analysis import calculate_accuracy\n",
    "from packages.functionality_analysis import calculate_confusion\n",
    "from packages.comprehensibility_analysis import plot_heatmap\n",
    "from packages.comprehensibility_analysis import dimension_reduction_pca\n",
    "from packages.neuralNetworkModel import neuralNetworkModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is simple machine learning abstract base model that has constructor __init__, train, and predict functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - extra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data();\n",
    "    \n",
    "x_test_task3 = x_test[0:100,:,:];\n",
    "y_test_task3 = y_test[0:100];\n",
    "\n",
    "x_test = x_test[100:,:,:];\n",
    "y_test = y_test[100:];\n",
    "\n",
    "x_train = x_train / 255.0;\n",
    "x_test = x_test / 255.0;\n",
    "x_test = tf.Variable(x_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neuralNetworkModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss=0.385, test set      accuracy=93.667%\n",
      "Epoch: 2, loss=0.159, test set      accuracy=96.010%\n",
      "Epoch: 3, loss=0.108, test set      accuracy=96.818%\n",
      "Epoch: 4, loss=0.079, test set      accuracy=97.131%\n",
      "Epoch: 5, loss=0.059, test set      accuracy=97.515%\n",
      "Epoch: 6, loss=0.048, test set      accuracy=97.455%\n",
      "Epoch: 7, loss=0.036, test set      accuracy=97.616%\n",
      "Epoch: 8, loss=0.029, test set      accuracy=97.848%\n",
      "Epoch: 9, loss=0.025, test set      accuracy=97.727%\n",
      "Epoch: 10, loss=0.019, test set      accuracy=97.657%\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "model.train(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the model for functionality analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 1.0%\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(model,x_test_task3,y_test_task3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes |TP     |FP     |FN     |TN     |\n",
      "_________________________________________\n",
      "0\t|8\t|0\t|0\t|92\t|\n",
      "_________________________________________\n",
      "1\t|14\t|0\t|0\t|86\t|\n",
      "_________________________________________\n",
      "2\t|8\t|0\t|0\t|92\t|\n",
      "_________________________________________\n",
      "3\t|11\t|0\t|0\t|89\t|\n",
      "_________________________________________\n",
      "4\t|14\t|0\t|0\t|86\t|\n",
      "_________________________________________\n",
      "5\t|7\t|0\t|0\t|93\t|\n",
      "_________________________________________\n",
      "6\t|10\t|0\t|0\t|90\t|\n",
      "_________________________________________\n",
      "7\t|15\t|0\t|0\t|85\t|\n",
      "_________________________________________\n",
      "8\t|2\t|0\t|0\t|98\t|\n",
      "_________________________________________\n",
      "9\t|11\t|0\t|0\t|89\t|\n"
     ]
    }
   ],
   "source": [
    "calculate_confusion(model,x_test_task3,y_test_task3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the model for comprehensibility analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-58d3d1f1cfcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\JupyterNote\\Neurocat\\packages\\comprehensibility_analysis.py\u001b[0m in \u001b[0;36mplot_heatmap\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdimension_reduction_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "plot_heatmap(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_reduction_pca(x_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra (Puzzle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_smoother(\n",
    "        input_image: np.ndarray,\n",
    "        kernel_height=5,\n",
    "        kernel_width=5,\n",
    "        stride_height=1,\n",
    "        stride_width=1) -> np.ndarray:\n",
    "    \n",
    "    assert input_image.ndim == 4\n",
    "    assert input_image.shape[0] == 1 and input_image.shape[-1] == 3\n",
    "    \n",
    "    input_node = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=input_image.shape\n",
    "    )\n",
    "    \n",
    "    # This objective is the only part you need to change.\n",
    "    # try to use as less for-loops as possible\n",
    "    kernels = input_image # this is just a placeholder\n",
    "    ...\n",
    "    mean_kernel = tf.reduce_mean(\n",
    "    kernels,\n",
    "    axis=(1, 2),\n",
    "    keepdims=True\n",
    "    )\n",
    "    objective = tf.square(input_node - mean_kernel)\n",
    "    # Please note that this objective would only be correct if\n",
    "    # (kernel_height, kernel_width) == input_image.shape[1:3]\n",
    "    # your approach must be flexible under kernel size and stride\n",
    "    gradient_node = tf.gradients(ys=objective, xs=input_node)\n",
    "    with tf.Session() as session:\n",
    "    for _ in tqdm(range(1000), desc=\"optimize image\"):\n",
    "    _gradient = session.run(\n",
    "    gradient_node,\n",
    "    feed_dict={\n",
    "    input_node: input_image\n",
    "    }\n",
    "    )\n",
    "    gradient_step = np.sign(_gradient[0]) * (1 / 255)\n",
    "    input_image = np.clip(input_image - gradient_step)\n",
    "    return input_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
